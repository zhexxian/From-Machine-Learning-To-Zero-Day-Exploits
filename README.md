From Machine Learning to Zero-Day Exploits
==========================================

This repository is a fork of [Larspars' word-rnn](https://github.com/larspars/word-rnn).

Background
----------
**Cyber Physical System (CPS) Protection**
Cyber-Physical Systems (CPS) are integrations of computation, networking, and physical processes (1). Examples of of CPS include autonomous automotive systems, medical monitoring, distributed robotics, and automatic pilot avionics (2).  Protection of CPS against cyber-attacks are essentially safeguarding the crucial networks such as aerospace, transportation, healthcare, and energy.

CPS is also similar to the Internet of Things (IoT) sharing the same basic architecture, hence the achievement in CPS protection may be potentially applied to the ever-growing field of IoT security as well. 


**Vulnerability and Exploits**
In cyber security, a vulnerability is a weakness and a flaw in a system, that could possibly provide an attacker with a way to bypass the security infrastructure, whereas an exploit takes advantage of the vulnerability and is an actual way to breach a system. (3)

The question we ask is: how to stop someone from exploiting a vulnerability in the software, when we do not know that the vulnerability exists?

Machine learning may shed light on discovering these zero-day vulnerabilities(4) as shown below.


**Machine Learning**
Machine learning is all about pattern recognition and data-driven predictions. It is widely applied in applications such as image classification, sentiment analysis, and machine translation.

For CPS protection, specifically in identifying zero-day exploits for unknown vulnerabilities, machine learning assist the process as shown in the flow chart:

![flowchart] (https://raw.githubusercontent.com/zhexxian/From-Machine-Learning-To-Zero-Day-Exploits/master/flowchart.png?token=ANANdkwsQ8a7mz6cYD1iNDBH49q_sZ2oks5XxqAOwA%3D%3D)


Recurrent Neural Network (RNN)
-------
[Karpathy](https://github.com/karpathy)'s blog post [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) provides a comprehensive overview of RNN and its applications, as summarized below.

**RNN vs Traditional**
If we are to describe RNN in one word, it will be _sequence_. 

Traditional machine learning neural networks, such as Vanilla Neural Networks, is very constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model).

The core reason that recurrent nets are more exciting is that they allow us to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both.

**Long Short-Term Memory (LSTM) Model**
One of the appeals of RNN is the idea that it may be able to connect previous information to the present task, but here's the catch: as the gap between the relevant information and the point where it is needed grows, it becomes increasingly harder for RNN to connect the information. [5] 

Fortunately, LSTM, a special kind of RNN, resolves the long term memory dependency issue by the use of states. It is the model we will use for zero-day exploit prediction.

**Word-RNN**
[Word-RNN](https://github.com/larspars/word-rnn) is based on [Karpathy's char-RNN](https://github.com/karpathy/char-rnn), that allows you to train character-level language models based on multi-layer LSTMs. Since exploits are scripts written in programming language, it can be modeled by word-RNN to predict new exploits.

Procedure
-------
**Set-Up**
The hardware used is NVIDIA Tesla K80 12GB GPU and Ubuntu server. 
The software includes CUDA and Torch. Refer to the [Requirements section](https://github.com/larspars/word-rnn) for installation instructions.

**Input**
Input data are extracted from [Exploits Database](https://www.exploit-db.com/) by web crawling and parsing.
The raw data is then sorted by programming language and concatenated into a single text file, automated by the [Python scripts](/input_file_processing_scripts).

**Training**

Below is an example of the command for model training:

```
$ th train.lua -data_dir data/concatenatedC -rnn_size 512 -num_layers 2 -dropout 0.5 -model "LSTM" -gpuid 0
```

 - ```th```: this is the command to run torch
 - ```train.lua```: the training logic is defined in this file
 - ```-data_dir```: this specifies the directory for input file, named "input.txt"
 - ```-rnn_size```: this defines the RNN model size; the ```rnn_size``` can be adjusted based on how much data you have
 - ```-num_layers```: this defines the number of layers in RNN; it is advised to always use ```num_layers``` of either 2 or 3
 - ```-dropout```: this defines the rate of dropout (or in terms of memory, "forget") in training
 - ```-model```: this defines the RNN model to use; common models include ```LSTM``` and ```GRU```
 - ```-gpuid```: this defines the index of GPU to be used (starting index is ```0```); ```-1``` is to use CPU



**Checkpoint**

While the model is training it will periodically write checkpoint files to the ```cv``` folder. 

A checkpoint file may have file name as such:
```
lm_lstm_epoch42.20_0.7792.t7
```
The number after ```epoch```--```42.20``` indicates the number of full passes the model has over the training data.

The next number ```0.7792```is the loss on validation. This number is very important because the lower it is, the better the checkpoint works. Notice that this might not necessarily be the last checkpoint at the end of training (due to possible overfitting).

**Sampling**

Given a checkpoint file (such as those written to cv) we can generate new text. For example:

```
$ th sample.lua cv/lm_lstm_epoch42.20_0.7792.t7 -gpuid -1
```

Results
-------

|Motivation|Language|Input Size (MB)|Input Content|RNN Size|RNN Model|Output|
|:---------|--------|---------------|:------------|--------|---------|:-----|
|Verify word-rnn and the "primetext" parameter|English|1.1|[tinyshakespeare](/data/tinyshakespeare/input.txt)|512|LSTM|[TinyShakespeare_VerifyPrimetext.txt](/output/TinyShakespeare_VerifyPrimetext.txt)|
|Train exploits|C|10.2|[remote exploit_C](/data/concatenatedC/input.txt)|512|LSTM|[RemoteExploitsC.txt](/output/RemoteExploitsC.txt)|
|Train exploits in Python|Python|2.9|[remote exploit_Python](/data/concatenatedPython/input.txt)|512|LSTM|[RemoteExploits_Python.txt](/output/RemoteExploits_Python.txt)|
|Reduce RNN model size|Python|2.9|[remote exploit_Python](/data/concatenatedPython/input.txt)|150|LSTM|[RemoteExploits_Python_smallerRNNmodelsize.txt](/output/RemoteExploits_Python_smallerRNNmodelsize.txt)|
|Train with a different model|Python|2.9|[remote exploit_Python](/data/concatenatedPython/input.txt)|512|GRU|[RemoteExploits_Python_GRU.txt](/output/RemoteExploits_Python_GRU.txt)|
|Change input data to a specific type of exploits|C|2.7|[dos exploit_C](/data/concatenatedC_DenialOfService/input.txt)|512|LSTM|[DenialOfService_Exploits_C.txt](/output/DenialOfService_Exploits_C.txt)|
|Remove comments in input data|C|8.2|[remote_exploit_C_noComments](/data/concatenatedC_NoComments/input.txt)|512|LSTM|[RemoteExploits_C_NoComments.txt](/output/RemoteExploits_C_NoComments.txt)|


> **Note:**
> A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU. It combines the forget and input gates into a single “update gate.”

>In the above experiments, both LSTM and GRU has been used for training, based on the model specified in the "RNN Model" column.

In addition to Torch, the Keras library (hfjhadjhskjhdj insert url from email here) has been used for training too. This is a sample output: [RemoteExploits_Python_Keras.txt](/output/RemoteExploits_Python_Keras.txt).

When training in word-rnn, the default parameter is "char-level" instead of "word-level". This is all right, as the concept of word and vocabulary is not applicable in programming language. Changing parameter to "word-level" has been tried, but was unsuccessful due to out of memeory error.



Conclusion
----------
Although there is huge potential in improving the syntax and logic of the machine-generated exploits, the project is a first step towards generating zero-day exploits from machine learning.

The exploits generated by RNN may be further improved by using technology such as [genetic algorithm](http://www.mathworks.com/discovery/genetic-algorithm.html?requestedDomain=www.mathworks.com) to systematically produce effective exploits.

Acknowledgement
---------------

This project is funded by [iTrust Centre for Research in Cyber Security](http://itrust.sutd.edu.sg/), directed by Aditya P. MATHUR, and mentored by Dr. Jonathan GOH.

Special thanks to Ivan LEE and TOH Jing Hui for knowledge sharing in areas including hacking and exploit technology, and Kaung Myat AUNG for hardware assistance. Thanks to Claudia AW and Muhammad Syuqri Bin JOHANNA for preparing input data.

Reference
---------

 1. [Cyber-Physical Systems](http://cyberphysicalsystems.org/)
 2. [Wikipedia Cyber-Physical Systems](https://en.wikipedia.org/wiki/Cyber-physical_system#Examples)
 3. [The difference between an expoit and vulnerability](http://www.livehacking.com/2012/11/20/the-difference-between-an-expoit-and-vulnerability/)
 4. [What is a Zero-Day Vulnerability?](http://www.pctools.com/security-news/zero-day-vulnerability/)
 5. [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)




